{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What to do with audio if you're sick of listening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### By: Aaron Alef (Email: aaron.alef@code.berlin - Slack: [@aaron](https://slack.com/app_redirect?team=T54B2S3T9&channel=U82F166U9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "**In June 2017 Mozilla launched their project [\"Common Voice\"](https://voice.mozilla.org/en) - an open-source project to provide audio data sets for speech recognition to everyone. As of May 2019 it contains over 1000 hours of validated speech in 20 different languages.  \n",
    "So wouldn't it be cool if this could be used to support you in listening, by using it for speech recognition?  \n",
    "The process of doing so is described in the 'Natural Language Processing' Folder - but in order to make use of this data it has to be processed...  \n",
    "This document aims at describing this process with it's facettes and tricks. And it *is* tricky**\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Voice is complex.\n",
    "Regardless of whether it's a human or an animal talking, the way they exchange their distinctive sounds can become very complex.  \n",
    "As I showed in the Jupyter Notebook about Natural Language Processing, the sound waves of a simple sentence being spoken looks rather like random data points than something meaningful and yet...  \n",
    "Just listening back to sound tells us it's *not* random data. Thus, the next logic step is doing something with this data. And, what'd be more intuitive than trying to recognize it?  \n",
    "Though in order to achieve what children fail with even after years of training, we need to ask the question, what *is* this data? How is sound stored digitally?  \n",
    "And, of course, we want to look at the data set we've got - What is it, and what can we use it for?\n",
    "\n",
    "Since this notebook is not directly about a problem, I will just visualise the data and see what we can learn from it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "Since the data sets can be quite large (up to around 20 GB) I recommend that you already start downloading it.  \n",
    "I'll use examples for the english language only, but feel free to test everything in other languages as well.\n",
    "Also, there are a few dependencies that need to be installed in order to run everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "COMMAND = \"pip install --user -r ../../requirements.txt\"\n",
    "\n",
    "from os import system\n",
    "system(COMMAND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either download it [here](https://voice.mozilla.org/en/datasets) or using the python script below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading a new data set in English to ./en\n",
      "from https://voice-prod-bundler-ee1969a6ce8178826482b88e843c335139bd3fb4.s3.amazonaws.com/cv-corpus-1/en.tar.gz...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "202705it [00:02, 99898.93it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrupted by user.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "1",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3304: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from transcription import prepare\n",
    "\n",
    "LANG='en'\n",
    "prepare.Prepare(LANG, mode=\"download\", show_progress=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sound\n",
    "\n",
    "But let's go away from the data set for now, and focus shortly on what voice is made up and how it's stored on a computer.\n",
    "\n",
    "Sound consists of sonic waves transmitted over a medium, mostly air. We can capture it using analog sensors, that is, a microphone.  \n",
    "Since we can't store waves (as waves are expanding oscillations) we need to find a way around that - which is called sampling. We take samples every few microseconds, at a so-called sample rate given in hertz and store this in a continous stream. We can look at this stream by loading an audio file (I've taken file a from the NLP notebook).\n",
    "Also, we can load a tsv file containing the audio in order to get some more information about it. I've taken the `validated.tsv` file as it contains all audio clips which we're validated by other people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transcription import visualise\n",
    "from os.path import join\n",
    "\n",
    "# TODO: Location of unzipped project:\n",
    "PATH_TO_PROJECT = \"../../Data/en\"\n",
    "\n",
    "FILE = \"77c44851bac797d08b5724fcd0412c0a073f7888adc34a5ab588669e08319729647c4bc28e10a4b0609a7cdd15016f91e5a945314fab8392e4225df53744e51f.mp3\"\n",
    "TABLE = \"validated.tsv\"\n",
    "\n",
    "audio = visualise.Visualise(join(PATH_TO_PROJECT, \"clips\", FILE), tsv=join(PATH_TO_PROJECT, TABLE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at the sampled data, the sample rate and its metadata stored in the validated.tsv:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Rate of the audio file: 22050\n",
      "[-0.01885764 -0.0272058  -0.0357662  -0.04296669 -0.04838737 -0.04560987\n",
      " -0.0375044  -0.02255747 -0.00750283  0.00444547  0.01054961  0.00404552\n",
      " -0.02160558 -0.06494284 -0.11601822 -0.15945661 -0.18460864 -0.18714596\n",
      " -0.16486757 -0.11757588]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>path</th>\n",
       "      <th>sentence</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>accent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2247</th>\n",
       "      <td>1f316ddca02594b5010fdecbe8c071bccbd29375500b13161ca26afe4737fa013101d69cb09eff35293238e7b14075018231b70abdba72fec1c3a4adbd7efaab</td>\n",
       "      <td>77c44851bac797d08b5724fcd0412c0a073f7888adc34a5ab588669e08319729647c4bc28e10a4b0609a7cdd15016f91e5a945314fab8392e4225df53744e51f</td>\n",
       "      <td>One of the first problems you'll run into is recognition errors, particularly with any command that allows raw dictation.</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                             client_id  \\\n",
       "2247  1f316ddca02594b5010fdecbe8c071bccbd29375500b13161ca26afe4737fa013101d69cb09eff35293238e7b14075018231b70abdba72fec1c3a4adbd7efaab   \n",
       "\n",
       "                                                                                                                                  path  \\\n",
       "2247  77c44851bac797d08b5724fcd0412c0a073f7888adc34a5ab588669e08319729647c4bc28e10a4b0609a7cdd15016f91e5a945314fab8392e4225df53744e51f   \n",
       "\n",
       "                                                                                                                       sentence  \\\n",
       "2247  One of the first problems you'll run into is recognition errors, particularly with any command that allows raw dictation.   \n",
       "\n",
       "      up_votes  down_votes  age gender accent  \n",
       "2247         2           0  NaN    NaN    NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr = audio.sample_rate\n",
    "\n",
    "print(\"Sample Rate of the audio file: \" + str(sr))\n",
    "\n",
    "# Print 20 samples starting at the fifth second:\n",
    "print(audio.data[(5*sr) : (5*sr + 20)])\n",
    "\n",
    "# Show the table entry of the audio file:\n",
    "audio.metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we might want to listen to it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio.play()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, to come back at what I said earlier, here a look at a diagram showing sampled audio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f5bfb81e2b0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.7/site-packages/IPython/core/events.py:88: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  func(*args, **kwargs)\n",
      "/usr/lib/python3.7/site-packages/IPython/core/pylabtools.py:128: UserWarning: Creating legend with loc=\"best\" can be slow with large amounts of data.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the samples of both audio files\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(audio.data, 'b', label='audio')\n",
    "plt.xlabel(\"Samples\")\n",
    "plt.ylabel(\"Amplitude\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set\n",
    "\n",
    "Let's get back to the data set.  \n",
    "I've already shown one line in it without explaining, so... what does it show?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['client_id', 'path', 'sentence', 'up_votes', 'down_votes', 'age',\n",
       "       'gender', 'accent'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "table = pd.read_csv(join(PATH_TO_PROJECT, TABLE), sep='\\t')\n",
    "table.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most important thing of those for *speech recognition* is the **path**, which is our key for the audio clip, and the **sentence**, containing the actual label of the audio file.  \n",
    "But there's more:\n",
    "* The **client id** is a unique identification number every contributor gets. \n",
    "* The **up** and **down votes** are telling us whether the people who listened to us liked it or not.\n",
    "* **Age** is a rough estimate at the age of the speaker; it's not given for everyone and not 100% accurate, but gives a nice estimate\n",
    "* The **gender** is also not given for everyone, but should otherwise be self-explanatory\n",
    "* The **accent** might give a clue where the person comes from - the german set, for example, provides a few clips from switzerland which are also labeled that way\n",
    "\n",
    "If we use `pandas`'s built in `describe` function, we see numerical explanations of the numbers used in the table, which is the up and down votes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>490483.000000</td>\n",
       "      <td>490483.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.653558</td>\n",
       "      <td>0.196910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.408856</td>\n",
       "      <td>1.125418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1613.000000</td>\n",
       "      <td>528.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            up_votes     down_votes\n",
       "count  490483.000000  490483.000000\n",
       "mean        2.653558       0.196910\n",
       "std         7.408856       1.125418\n",
       "min         2.000000       0.000000\n",
       "25%         2.000000       0.000000\n",
       "50%         2.000000       0.000000\n",
       "75%         3.000000       0.000000\n",
       "max      1613.000000     528.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This let's us get an overview overwhat the numbers mean:\n",
    "\n",
    "Even though we have an average of only 2.65 up votes per clip, the numbers go up to 1613.  \n",
    "Luckily, for the down votes the numbers are a lot smaller, with an average of under 0.2 votes per clip.\n",
    "\n",
    "But of course we can also look at the other fields:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id     490483\n",
       "path          490483\n",
       "sentence      490480\n",
       "up_votes      490483\n",
       "down_votes    490483\n",
       "age           249443\n",
       "gender        250749\n",
       "accent        215116\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What might look weird at the first glance is a fact I mentioned above: not every audio clip is fully labeled, and pandas automatically excludes missing entries from the count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-3f4a57369902>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualise\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgender\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Workspace/NotepadAI/test-nlp/Jupyter-Notebook/Data Science/transcription/visualise.py\u001b[0m in \u001b[0;36mbar_graph\u001b[0;34m(column)\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mcategories\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0mbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcategories\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m     \u001b[0mbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    390\u001b[0m                                  dtype=dtype, copy=copy)\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    393\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 212\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.7/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindexes\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mraw_lengths\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m             raise ValueError('If using all scalar values, you must pass'\n\u001b[0m\u001b[1;32m    309\u001b[0m                              ' an index')\n\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "visualise.bar_graph(table.gender)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## Conclusion\n",
    "\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "* https://www.talend.com/resources/what-is-data-processing/\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
